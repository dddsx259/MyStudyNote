{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cb9996",
   "metadata": {},
   "source": [
    "# Perceptron 感知机\n",
    "> Perceptron design by is generally considered the **origin** of the **neural networks** and **modern machine learning**(*Python Machine Learning*, *Pattern Recognition and Machine Learning*). \n",
    "> This note is my(dddsx259) studying note about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7fefc",
   "metadata": {},
   "source": [
    "## 1. Definitions\n",
    "Consider a **neuron** node. It takes a array/vector as input and output a **decision function** to binary classify the input:\n",
    "+ INPUT: a vector $x$:\n",
    "$$\n",
    "x=\n",
    "\\begin{bmatrix}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "\\dots\\\\\n",
    "x_m\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "+ OUTPUT: a classification result(as decision function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x: list[int], )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959c11a",
   "metadata": {},
   "source": [
    "### Definition 1: Decision function\n",
    "$$\n",
    "\\Phi(z)=\n",
    "\\begin{cases}\n",
    "&1 &if z\\ge\\theta\\\\\n",
    "&-1 &otherwise \n",
    "\\end{cases}\n",
    "$$\n",
    "The $\\theta$ is **threshold**, the $z$ is the **net input**:\n",
    "$$\n",
    "z=\\vec{w}\\cdot\\vec{x}\\ or\\ \\vec{w}^T\\vec{x}\n",
    "$$\n",
    "Where $\\vec{w}$ is the parameters of the perceptron model.\n",
    "\n",
    "We cna also simplize the notation by bring the threshold $\\theta$ to the $w_0x_0$:\n",
    "$$\n",
    "z=w_0x_0+w_1x_1+\\dots+w_mx_m\\\\\n",
    "\\Phi(z)=\n",
    "\\begin{cases}\n",
    "&1 &if z\\ge0\\\\\n",
    "&-1 &otherwise \n",
    "\\end{cases}\n",
    "$$\n",
    "where $w_0$ called **bias unit** $=-\\theta$ and $x_0 = 1$\n",
    "i.e. Actually we can represent the input $z$:\n",
    "$$\n",
    "z = \\vec{w}^T\\vec{x} - \\theta = \\vec{w}^T\\vec{x} + b\n",
    "$$\n",
    "We called $b$ the **bais**\n",
    "\n",
    "After those definition, we next consider the parameter update rule of perceptron:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883af6e",
   "metadata": {},
   "source": [
    "## 2. Perceptron Learning Rule\n",
    "The core idea of perceptron is **adjust the parameter** by **correctness of each sample**. For the i-th sample $x^{(i)}$, we follow the process below:\n",
    "1. Initialize all parameters\n",
    "   1. Hyper-parameter:\n",
    "      1. **Learning rate** $\\eta$\n",
    "   2. Self-learning Parameters:\n",
    "      1. Weights: $\\vec{w}\n",
    "      2. Bias: $\\theta$\n",
    "2. Compute the predict output value: $\\hat{y}T{(i)}\\in\\{+1,-1\\}$\n",
    "3. Update the weights, follow:\n",
    "   1. $$\\vec{w}\\leftarrow\\vec{w}+\\Delta \\vec{w}$$\n",
    "      1. We have:$$\\Delta \\vec{w}=\\eta(y^{(i)}-\\hat{y}^{(i)})\\vec{x}^{(i)}$$\n",
    "      2. Where:\n",
    "         1. $\\eta$ is the **learning rate**\n",
    "         2. $y^{(i)}$ is the true class of the sample $x^{(i)}$\n",
    "         3. Note that the only value range of $y$ is $\\{+1,-1\\}$, so actually $\\Delta \\vec{w}=\\pm 2\\eta\\vec{x}^{(i)}$\n",
    "   2. $$b \\leftarrow b + \\Delta b$$\n",
    "      1. Same asn the update rule of $\\vec{w}$, we have: $$\\Delta b=\\eta(y^{(i)}-\\hat{y}^{(i)})$$\n",
    "4. Repeat the above step for many round."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f56217",
   "metadata": {},
   "source": [
    "# 3. Parameters\n",
    "## 3.1 Hyper-parameters\n",
    "The **hyper-parameters** is the parameter that we fix the value before model training, and never change. It based on the experience of the trainer. The hyper parameter in this model is the **learning rate**.\n",
    "+ If the learning rate is too small, then each round of training's influnence on the parameter will be small so that we need more time to train the model\n",
    "+ If the learning rate is too huge, then each sample can make a big change to the weight, so that is may only fit some samples.\n",
    "  \n",
    "\n",
    "## 3.2 Parameter\n",
    "The parameters is the **learnable/model/internal parameters**. After we set the initial value of them, it was change by model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b3baf",
   "metadata": {},
   "source": [
    "This note's structure based on HKU COMP3314 Lec2. With many extra content from:\n",
    "> UCB CS189    \n",
    "> AI generate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
