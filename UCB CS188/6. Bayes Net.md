# 1. Probability Rundown
We just list some formula, no explanation.
1. $$P(A, B, C) = P(C, B, A)$$
2. $$P(A_1, A_2, \dots, A_k) = P(A_1) P(A_2|A_1) \cdots P(A_k | A_1, \dots, A_{k-1})$$
3. **Marginalization** or **Summing out**     
   $$P(A)=\sum_b\sum_c\cdots P(A,B=b,C=c,\cdots)$$
4. **Conditional Probability**.   
   $$P(A|B) = \frac{P(A, B)}{P(B)} \quad (P(B) > 0)$$
5. **Bayes' Rule**
   +  $$P(A|B) = \frac{P(B|A) P(A)}{P(B)}$$
6. **Mutual Independence**
   A and B are independent IFF :
    - $P(A, B) = P(A) P(B)$
    - $P(A|B) = P(A)$, provided $P(B)>0$
    - $P(B|A) = P(B)$, provided $P(A)>0$
7. A is independence of B given $C_1,C_2,\cdots$: $A \perp\!\!\!\perp B \mid C_1,C_2,\cdots$

# 2. Probabilistic Inference
We consider that our world isn't in a specific state, i.e. each possible state in our world has its own probability. More precisely, our model is a **joint distribution,** i.e., a table of probabilities that captures the likelihood of each possible outcome, also known as an complete assignment. As an example, consider the table below:

| Season | Temperature | Weather | Probability |
|--------|-------------|---------|-------------|
| summer | hot         | sun     | 0.30        |
| summer | hot         | rain    | 0.05        |
| summer | cold        | sun     | 0.10        |
| summer | cold        | rain    | 0.05        |
| winter | hot         | sun     | 0.10        |
| winter | hot         | rain    | 0.05        |
| winter | cold        | sun     | 0.15        |
| winter | cold        | rain    | 0.20        |

## 2.1 Inference by Enumeration, IBE
We can use IBE to compute each probability we want by a complete **joint Probability Distribution Function**.

There are three kinds of variables:
$$P(Q|E=e)$$
+ **Query Variables**: The variable that we want to know the joint probability distribution
+ **Evidence Variables**: The known observed variables
+ **Hidden Variables**: Exists in joint PDF, but is neither QV nor EV.

The process of IBE:
To compute $P(Q_1,\cdots, Q_m|e_1,\cdots, e_n)$.   
1. **Filter**: Only preserve the rows **matching the observed evidence value**.
2. **Marginalize**: Sum up values of the hidden variable.
3. **Normalize**: Divide each item by the sum, s.t. the total probability is $1$

# 3 Bayesian Network Representation
Though we can solve any probability problem by IBE, the joint PDF is really huge.
> If we have $n$ random variables, each with $d$ possible value. The joint PDF will contain $d^n$ rows!

So we try to use a new structure to represent it!

## 3.1 Bayes Network
Two key idea of Bayes Net:
1. Use **DAG(Directed acyclic graph)** to represent the dependency relationship between variables.
   1. Each node in DAG represents an **random variable**
   2. Each directed edge represents a **direcy dependency relationship**(may not causality)
   3. MUst be **acyclic** !
2. Use multiple small **CPT(Conditional probability table)** instead of a huge joint PDF.
   1. For each variable $X$, the CPT gives all its **conditional probability** given its parent nodes' value
   2. The CPT contains:
      1. The combinations of all the values of the parent variables.
      2. Value of $X$
      3. The corresponding conditional probability.

## 3.2 How to compute probability (by Bayes Net)
The core formula(**Chain decomposition**)
$$
P(X_1, X_2, \dots, X_n) = \prod_{i=1}^{n} P\big(X_i \mid \text{Parents}(X_i)\big)
$$

## 3.3 Structure of Bayes Nets
Two important dependency relationship of Bayes Net:
1. Each node is conditional independent of all its non-descendant nodes in the DAG, given all of its parents.
2. **Markov Blanket**
   1. Each node is conditionally independent of all nodes, given its **Markov Blanket**.
   2. The Markov Blanket includes 3 kinds of nodes:
      1. Parents
      2. Children
      3. The other parents of its children (Co-parents), also called **Spouses**

Now we can prove why we can decompose joint PDF into CPTs:
We want to prove:
$$
P(X_1,X_2,...X_n)=\prod P\big(X_i|Parents(X_i)\big)
$$
Where $(X_1,X_2,\dots X_n)$ are in topological order.

LHS can be represent as:
$$
P(X_1)\cdot P(X_2|X_1)\cdot P(X_3|X_2,X_1)\cdot\dots
$$

By the **local Markov property**, each $X_i$ is conditionally independent of its non-desendants given its parents. Since the variables are ordered topologically, all ancestors of $X_i$ appear before it and thus:
$$
\forall i, P(X_i|X_{i-1},\dots X_1) = P\big(X_i|Parents(X_i)\big)\\
$$
Substituting into the chain rule yields the desired factorization.  
Q.E.D


# 4. D-Separation
## 4.1 Basical structure
How to judge weather two variables are conditional independent? We can use **D_Separation** to judge them only by **the structure of Bayes Net**.
Consider the following 3 **canonical triples**:
1. Causal Chain 因果链
   1. Structure: $X\rightarrow Y\rightarrow Z$
      1. Not observe $Y$: X and Z are dependent(i.e. informtion transmitted along the chain). 
      2. Given $Y$: $X\perp\!\!\!\perp Z\mid Y$.       
i.e. The two endpoint independent IFF the middle node are observed.

2. Common cause/Fork 共同原因
   1. Structure: $X\leftarrow Y\rightarrow Z$
      1. Not observe $Y$: X and Z are dependent
      2. Given $Y$: $X\perp\!\!\!\perp Z\mid Y$.   
i.e. The children independent IFF the co-parent are observed. 

3. Common effect/Collider
   1. Structure: $X\rightarrow Z\leftarrow Z$
      1. Not observe $Y$: $X\perp\!\!\!\perp Z$
      2. Given $Y$(or any of its descendants): $X$ and $Z$ are dependent

## 4.2 The general rule of D-separation 
We want to judje weather $X$ and $Y$ are conditional independent given evidence set $\mathbb{Z}=\{Z_1,Z_2,\dots Z_k\}$.   
Precess:
1. Mark all evidence variables as **shaded**
2. Find all undirected path from $X$ to $Y$
3. For all path, check if it's **blocked**
   1. We divided each path into continuous triples.
   2. The path is blocked IFF there exist at least one blocked triple
4. If all path are blocked, then $X\perp\!\!\!\perp Y\mid\mathbb{Z}$


| Structure | middle node $Y$  | active or blocked？ |
|---|---|---|
| **Causal chain** ($X\rightarrow Y\rightarrow Z$) or **Common cause** ($X\leftarrow Y\rightarrow Z$) | not observed| active |
| **Causal chain** ($X\rightarrow Y\rightarrow Z$) or **Common cause** ($X\leftarrow Y\rightarrow Z$) | observed    | blocked |
| **Common Effect**($X\rightarrow Y\leftarrow Z$) | not observed | blocked |
| **Common Effect**($X\rightarrow Y\leftarrow Z$) | observed（or its descendent is observed） | active |

# 5. Exact inference in Bayes Net
The most directly way to exactly compute the posterior probability is IBE, but is too complex when the number of variable increase.

## 5.1 Variable Elimination
Instead of structure the complete joint distribution, we can **elimination variables step by step**. Only handle the **local factors** involving this variable, thus avoiding the storage of large tables.

What is "factor"? It‘s an unnormalized function that is proportional to the really probability. Factors specify the local relationship of probability, e.g. CPT is a natural factor.
Here is the pseudocode of variable elimination:
```pseudocode
function elimination_ask(X, e, bn)
inputs: 
   X, the query variable
   e, observed values for evidence variables E
   bn, a Bayesian network specifying joint distribution P(X1,X2,...Xn)
return: a distribution over X

   factors = []
   for each var in elimination_order(bn, Vars) do
      factors = make_factor(var,e) + factors
      if var is a hidden variable
      then  
         factors = sum_out(var, factors)
      end if
   end for
   return normalize(pointwise_product(factors))
end function
```

There are two core step of variable elimination:
1. Join (multiply together) all factors involving $X$, get a new factor
2. Sum out $X$, then get a new factor that not contain $X$.

## 5.2 Mathematical perspective: Rearrange the summation order
let $P(X_1,X_2,\dots X_n) = \prod^m_{i=1}f_i(C_i)$, where $f_I$ is a factor, $C_i\subseteq\{X_1,\dots X_n\}$.    
By IBE, the marginal distribution of a certain query variable $Q$ given evidence variables $E=e$ is:
$$
P(Q\mid E=e)\propto\sum_\mathbb{H}P(Q,\mathbb{H},E=e)=\sum_\mathbb{H}\big[\prod_{i=1}^mf_i(C_i)\ \big|_{E=e}\big]
$$
Note that by distributivity, 
$$
\sum_x (f_\text{x in parameter}\cdot f_\text{x notin parameter}) = f_\text{x notin parameter}\cdot\sum_x f_\text{x in parameter}
$$
So we can divide the huge summation into local summation about only some variables. The above algebraic transformation is the essence as eliminating the variable $x$.

# 6. Approximate Inference in Bayes Nets: Sampling

When the Bayes net is big enough, so that it's impossible to exactly inference. So we try to use **sampling** to generate samples, approximate the probability statistically.

## 6.1 Prior Sampling
+ Sample from each variable's CPT, follow the topological sort order in Bayes net(parent to children). Generate the samples of **complete joint distribution** $P(X_1,X_2,\dots X_n)$
+ For inference:
  + To compute $P(Q\mid e_1,e_2,\dots e_n)$
  + Generate $N$ samples, only preserve the sample satisfy $\forall i, E_i=e_i$
+ Count the proportion of each value of $Q$.
+ Drawback: If the probability of certain evidence value is too low(e.g. $P(e_i) = 0.001$), a lot of samples will be discard.

## 6.2 Rejection Sampling
During sampling, **stop generating samples once a contradiction is found with the evidence**
It speed up the process of generating samples, but **still inefficient for rare evidence**.

## 6.3 Likehood Weighting
We consider: **Force each evidence variable to be assigned observed value**, and assign a **weight** to each samples, which reflect the **reasonableness** of the evidence in the current context.

Precess: $P(Q\mid e_1,\dots e_n), H_1,\dots H_m\text{ are hidden variables}$
1. Initialize weight: $w=1$
2. Handle variables follow the topological sort order: for each variable:
   1. **Non-evidence variable**: Sample normally.
   2. **Evidence variable**: $E_i = e_i$
      1. Don't sample, just assume it's observed value.
      2. Multiply the weight by $P(e_i\mid parents(E_i))$
3. The final sample is $(q, h_1,\dots, h_m)$
4. Then use **weighted average** rather than simple counting.

+ Advantage:
  + More efficient then the previous two methods
+ Backward
  + If the evidence variables are **ancestors of the query variable**(e.g. root node), then the weights may have a large variance.

## 6.4 Gibbs Sampling--Markov chain Monte Cario(MCMC)
**Core idea**:
+ Instead of generating samples from the prior, we **start from an arbitrarily initial state, gradually approach the really posterior distribution through iterative updates**.

Process:
1. Initialize all non-evidence variables an arbitrary value (can contradict with CPT), initialize evidence variable observed value.
2. Repeat the following precess(record after **burn-in stage**):
   1. Randomly choose a non-evidence variable $X$
   2. compute $P(X\mid Markov\_Blanket(X))$
   3. Resample $X$ from this conditional dirstribution.
3. Approximate probability after get enough samples.

+ Advantages:
  + Only need local information(Markov blanket of each variable)
  + Suitable for **high-dimensional and dense networks**.
  + No need for global weights
+ Backwards:
  + Convergence speed slow
  + The initial samples(burn-in samples) is deviate, need be discarded..
  + If there is a strong correlation among variables, may get stuck in a local area(**slow mixing**)