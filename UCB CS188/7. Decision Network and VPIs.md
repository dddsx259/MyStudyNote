# 1. Utilities
We define the mathematical language of preferences:
+ If an agent prefers receiving a prize $A$ to receiving a prize $B$, this is written $A\succ B$
+ If an agent is indifferent between receiving $A$ or $B$ this is written as $A\sim B$
+ A **lottery** is a situation with different prizes resulting with different probabilities. To denote a lottery where $A$ is received with probability $p$ and $B$ is received with probability $(1-p)$, we write: $L = [p, A; (1-p), B]$

## 1.1 Five Axioms of Rationality
In order for a set of preferences to be rational, they must follow the five **Axioms of Rationality 理性公理**:

- **Orderability**:  
  $$(A \succ B) \vee (B \succ A) \vee (A \sim B)$$  
  A rational agent must either prefer one of $A$ or $B$, or be indifferent between the two.
  
- **Transitivity 传递性**:  
  $$(A \succ B) \wedge (B \succ C) \Rightarrow (A \succ C)$$  
  If a rational agent prefers $A$ to $B$ and $B$ to $C$, then it prefers $A$ to $C$.

- **Continuity 连续性**:  
  $$A \succ B \succ C \Rightarrow \exists p \: [p, A; (1-p), C] \sim B$$  
  If a rational agent prefers $A$ to $B$ but $B$ to $C$, then it's possible to construct a lottery $L$ between $A$ and $C$ such that the agent is indifferent between $L$ and $B$ with appropriate selection of $p$.

- **Substitutability 替代性**:  
  $$A \sim B \Rightarrow [p, A; (1-p), C] \sim [p, B; (1-p), C]$$  
  A rational agent indifferent between two prizes $A$ and $B$ is also indifferent between any two lotteries which only differ in substitutions of $A$ for $B$ or $B$ for $A$.

- **Monotonicity 单调性**:  
  $$A \succ B \Rightarrow \big((p \geq q) \Leftrightarrow [p, A; (1-p), B] \succeq [q, A; (1-q), B]\big)$$  
  If a rational agent prefers $A$ over $B$, then given a choice between lotteries involving only $A$ and $B$, the agent prefers the lottery assigning the highest probability to $A$.

## 1.2 Utility function
Expected Utility Theorem:
> If all five axioms are satisfied by an agent, then there must exist a **real-value utility function** $U$, satisfy:
1. $$U(A)\ge U(B) \Leftrightarrow A\succ B$$
2. $$U([p_1, S_1;\dots p_n,S_n] = \sum_ip_iU(S_i))$$

That means **Rational actions = Maximize expect utility**!


# 2. Decision Networks
We consider combinating the Bayes Net and expectmax. 
Three types of node in decision network:
+ **Chance nodes**:
   + Represent **random event**
   + The probability of what happened can be inferent by Bayes Net
+ **Action nodes**:
  + Represent the choice we make.
  + The decision variable that we want to optimize
+ **Utility ndoes**
  + The children of chance nodes and action nodes
  + Output a value of utility, depends on its parents.

## 2.1 Process of do decision
+ Goal: Select the action that yields the **maximum expected utility (MEU)**.
1. Fix the known evidence, calculate the posterior probabilities (of all chance node parents of the utility node)
2. For each possible action, compute its **expect utility (EU)**
    $$
    EU(a \mid e) = \sum_{x_1, ..., x_n}P(x_1, ..., x_n \mid e)U(a, x_1, ..., x_n)
    $$
    where:
    + $a$ is an action
    + $e$ is known evidence
    + $x_i$ is the value of the chance node
3. Select the action with the highest EU.

## 2.2 Outcome Tree
We can expansion the decision net into a **outcome tree**, like a expectmax tree.
+ **root node** -> maximizer node, represent we select action
+ **next layer** -> chance node
+ **leaves** -> utilities


# 3. The Value of Perfect Information
Though know more information will make our decision more determinated, usually obtaining information incurs cost. So there is a problem: Is it worth it?

VPI: the expect increment of MEU after get certain new evidence variable.

If the VPI > the cost of obtaining information, then it worth.

## 3.1 General Formula
+ Let the known evidence value set is $e$, the current MEU is:
  $$
  MEU(e)=\max_a\sum_sP(s|e)\cdot U(a,s)
  $$
  where $s$ is world state.
+ Then after we obtain the new evidence $E'$, the new MEU is:
  $$
  MEU(e,E')=\sum_{e'}P(e'|e)\cdot MEU(e,e')
  $$
+ VPI is:
  $$
  VPI(E'\mid e)=MEU(e,E')-MEU(e)

## 3.2 Propertire of VPI:
### 3.2.1. Nonnegativity 非负性
$$
\forall E', e,\quad VPI(E' \mid e) \geq 0
$$
i.e. Obtain more **correct** informtion **never make the decision worse**

### 3.2.2. Nonadditivity 不可加性
$$
VPI(E_j, E_k \mid e) \neq VPI(E_j \mid e) + VPI(E_k \mid e)
$$

### 3.2.3 Order-independence 顺序无关性
$$
VPI(E_j, E_k \mid e) = VPI(E_j \mid e) + VPI(E_k \mid e, E_j) \\
= VPI(E_k \mid e) + VPI(E_j \mid e, E_k)
$$